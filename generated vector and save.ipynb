{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载PV_DBOW模型\n",
    "pv_dbow_model = Doc2Vec.load('./PV_DBOW_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Discuss</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201e8bf2-77a2-3a98-9fcf-4ce03914e712</td>\n",
       "      <td>好大的一个游乐公园，已经去了2次，但感觉还没有玩够似的！会有第三，第四次的</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f4d51947-eac4-3005-9d3c-2f32d6068a2d</td>\n",
       "      <td>新中国成立也是在这举行，对我们中国人来说有些重要及深刻的意义！</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74aa7ae4-03a4-394c-bee0-5702d3a3082a</td>\n",
       "      <td>庐山瀑布非常有名，也有非常多个瀑布，只是最好看的非三叠泉莫属，推荐一去</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>099661c2-4360-3c49-a2fe-8c783764f7db</td>\n",
       "      <td>个人觉得颐和园是北京最值的一起的地方，不过相比下门票也是最贵的，比起故宫的雄伟与气势磅礴，颐...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97ca672d-e558-3542-ba7b-ee719bba1bab</td>\n",
       "      <td>迪斯尼一日游</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  201e8bf2-77a2-3a98-9fcf-4ce03914e712   \n",
       "1  f4d51947-eac4-3005-9d3c-2f32d6068a2d   \n",
       "2  74aa7ae4-03a4-394c-bee0-5702d3a3082a   \n",
       "3  099661c2-4360-3c49-a2fe-8c783764f7db   \n",
       "4  97ca672d-e558-3542-ba7b-ee719bba1bab   \n",
       "\n",
       "                                             Discuss  Score  \n",
       "0              好大的一个游乐公园，已经去了2次，但感觉还没有玩够似的！会有第三，第四次的      5  \n",
       "1                    新中国成立也是在这举行，对我们中国人来说有些重要及深刻的意义！      4  \n",
       "2                庐山瀑布非常有名，也有非常多个瀑布，只是最好看的非三叠泉莫属，推荐一去      4  \n",
       "3  个人觉得颐和园是北京最值的一起的地方，不过相比下门票也是最贵的，比起故宫的雄伟与气势磅礴，颐...      5  \n",
       "4                                             迪斯尼一日游      5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取训练文本\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/YNU.EDU2018-ScenicWord/train_first.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本分词\n",
    "#对字符串数据content分词\n",
    "import re\n",
    "import jieba\n",
    "def fenci_content(content):\n",
    "    seg_list = []\n",
    "    addlist = ['\\n',',',\"\\n\"]\n",
    "    text = re.sub(u'[a-zA-Z0-9.。：:;；，,)）(（！!?？”“\\\"\\<\\>《》/]','',content).split()  \n",
    "    for t in text:\n",
    "        seg = list(jieba.cut(t))\n",
    "        for s in seg:\n",
    "            if s not in addlist and len(s)>1:\n",
    "                seg_list.append(s)\n",
    "    return seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy\n",
    "#将数据划分成训练数据和测试数据\n",
    "train,test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Discuss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9a1caf96-681e-3c11-b588-43ac742d7fd2</td>\n",
       "      <td>快乐之旅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82b450db-65c2-351c-84fb-761d76582680</td>\n",
       "      <td>岛上看日落的地方，视野很开阔，非常漂亮</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2eec4606-590c-3fa2-b846-7f92441c54a6</td>\n",
       "      <td>很有鲁迅风味 很喜欢这样有文化的地方</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>509f9a68-ac41-35ff-9d2e-2fc12f73ed7f</td>\n",
       "      <td>去乌鲁木齐还能不去天山天池吗，哈哈哈～</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>395f4b22-1c5f-328a-a19d-5065e0530cbc</td>\n",
       "      <td>非常满意，直接拿身份证刷机入园就行了，不用排队买票，比较节约时间</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id                           Discuss\n",
       "0  9a1caf96-681e-3c11-b588-43ac742d7fd2                              快乐之旅\n",
       "1  82b450db-65c2-351c-84fb-761d76582680               岛上看日落的地方，视野很开阔，非常漂亮\n",
       "2  2eec4606-590c-3fa2-b846-7f92441c54a6                很有鲁迅风味 很喜欢这样有文化的地方\n",
       "3  509f9a68-ac41-35ff-9d2e-2fc12f73ed7f               去乌鲁木齐还能不去天山天池吗，哈哈哈～\n",
       "4  395f4b22-1c5f-328a-a19d-5065e0530cbc  非常满意，直接拿身份证刷机入园就行了，不用排队买票，比较节约时间"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取待预测的数据\n",
    "import pandas as pd\n",
    "df_predict = pd.read_csv('./data/YNU.EDU2018-ScenicWord/predict_first.csv')\n",
    "df_predict.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "import collections\n",
    "import multiprocessing\n",
    "#标签，doc2vec要求训练数据附上标签\n",
    "def tokenize1(data,tokens_only=False):\n",
    "    data_len = len(data)\n",
    "    corpus = []\n",
    "    for i in range(data_len):\n",
    "        d = data.iloc[i]\n",
    "        content = d.Discuss.decode('utf8')\n",
    "        if tokens_only:\n",
    "            corpus.append(fenci_content(content))\n",
    "        else:\n",
    "            #对训练数据打标签\n",
    "            corpus.append(gensim.models.doc2vec.TaggedDocument(fenci_content(content),[i]))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.514 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "train_corpus = list(tokenize1(train))\n",
    "test_corpus = list(tokenize1(test,tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.333 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "predict_corpus = list(tokenize1(df_predict,tokens_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc向量生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练/测试文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train processing 499\n",
      "train processing 999\n",
      "train processing 1499\n",
      "train processing 1999\n",
      "train processing 2499\n",
      "train processing 2999\n",
      "train processing 3499\n",
      "train processing 3999\n",
      "train processing 4499\n",
      "train processing 4999\n",
      "train processing 5499\n",
      "train processing 5999\n",
      "train processing 6499\n",
      "train processing 6999\n",
      "train processing 7499\n",
      "train processing 7999\n",
      "train processing 8499\n",
      "train processing 8999\n",
      "train processing 9499\n",
      "train processing 9999\n",
      "train processing 10499\n",
      "train processing 10999\n",
      "train processing 11499\n",
      "train processing 11999\n",
      "train processing 12499\n",
      "train processing 12999\n",
      "train processing 13499\n",
      "train processing 13999\n",
      "train processing 14499\n",
      "train processing 14999\n",
      "train processing 15499\n",
      "train processing 15999\n",
      "train processing 16499\n",
      "train processing 16999\n",
      "train processing 17499\n",
      "train processing 17999\n",
      "train processing 18499\n",
      "train processing 18999\n",
      "train processing 19499\n",
      "train processing 19999\n",
      "train processing 20499\n",
      "train processing 20999\n",
      "train processing 21499\n",
      "train processing 21999\n",
      "train processing 22499\n",
      "train processing 22999\n",
      "train processing 23499\n",
      "train processing 23999\n",
      "train processing 24499\n",
      "train processing 24999\n",
      "train processing 25499\n",
      "train processing 25999\n",
      "train processing 26499\n",
      "train processing 26999\n",
      "train processing 27499\n",
      "train processing 27999\n",
      "train processing 28499\n",
      "train processing 28999\n",
      "train processing 29499\n",
      "train processing 29999\n",
      "train processing 30499\n",
      "train processing 30999\n",
      "train processing 31499\n",
      "train processing 31999\n",
      "train processing 32499\n",
      "train processing 32999\n",
      "train processing 33499\n",
      "train processing 33999\n",
      "train processing 34499\n",
      "train processing 34999\n",
      "train processing 35499\n",
      "train processing 35999\n",
      "train processing 36499\n",
      "train processing 36999\n",
      "train processing 37499\n",
      "train processing 37999\n",
      "train processing 38499\n",
      "train processing 38999\n",
      "train processing 39499\n",
      "train processing 39999\n",
      "train processing 40499\n",
      "train processing 40999\n",
      "train processing 41499\n",
      "train processing 41999\n",
      "train processing 42499\n",
      "train processing 42999\n",
      "train processing 43499\n",
      "train processing 43999\n",
      "train processing 44499\n",
      "train processing 44999\n",
      "train processing 45499\n",
      "train processing 45999\n",
      "train processing 46499\n",
      "train processing 46999\n",
      "train processing 47499\n",
      "train processing 47999\n",
      "train processing 48499\n",
      "train processing 48999\n",
      "train processing 49499\n",
      "train processing 49999\n",
      "train processing 50499\n",
      "train processing 50999\n",
      "train processing 51499\n",
      "train processing 51999\n",
      "train processing 52499\n",
      "train processing 52999\n",
      "train processing 53499\n",
      "train processing 53999\n",
      "train processing 54499\n",
      "train processing 54999\n",
      "train processing 55499\n",
      "train processing 55999\n",
      "train processing 56499\n",
      "train processing 56999\n",
      "train processing 57499\n",
      "train processing 57999\n",
      "train processing 58499\n",
      "train processing 58999\n",
      "train processing 59499\n",
      "train processing 59999\n",
      "train processing 60499\n",
      "train processing 60999\n",
      "train processing 61499\n",
      "train processing 61999\n",
      "train processing 62499\n",
      "train processing 62999\n",
      "train processing 63499\n",
      "train processing 63999\n",
      "train processing 64499\n",
      "train processing 64999\n",
      "train processing 65499\n",
      "train processing 65999\n",
      "train processing 66499\n",
      "train processing 66999\n",
      "train processing 67499\n",
      "train processing 67999\n",
      "train processing 68499\n",
      "train processing 68999\n",
      "train processing 69499\n",
      "train processing 69999\n",
      "train processing 70499\n",
      "train processing 70999\n",
      "train processing 71499\n",
      "train processing 71999\n",
      "train processing 72499\n",
      "train processing 72999\n",
      "train processing 73499\n",
      "train processing 73999\n",
      "train processing 74499\n",
      "train processing 74999\n",
      "test processing 499\n",
      "test processing 999\n",
      "test processing 1499\n",
      "test processing 1999\n",
      "test processing 2499\n",
      "test processing 2999\n",
      "test processing 3499\n",
      "test processing 3999\n",
      "test processing 4499\n",
      "test processing 4999\n",
      "test processing 5499\n",
      "test processing 5999\n",
      "test processing 6499\n",
      "test processing 6999\n",
      "test processing 7499\n",
      "test processing 7999\n",
      "test processing 8499\n",
      "test processing 8999\n",
      "test processing 9499\n",
      "test processing 9999\n",
      "test processing 10499\n",
      "test processing 10999\n",
      "test processing 11499\n",
      "test processing 11999\n",
      "test processing 12499\n",
      "test processing 12999\n",
      "test processing 13499\n",
      "test processing 13999\n",
      "test processing 14499\n",
      "test processing 14999\n",
      "test processing 15499\n",
      "test processing 15999\n",
      "test processing 16499\n",
      "test processing 16999\n",
      "test processing 17499\n",
      "test processing 17999\n",
      "test processing 18499\n",
      "test processing 18999\n",
      "test processing 19499\n",
      "test processing 19999\n",
      "test processing 20499\n",
      "test processing 20999\n",
      "test processing 21499\n",
      "test processing 21999\n",
      "test processing 22499\n",
      "test processing 22999\n",
      "test processing 23499\n",
      "test processing 23999\n",
      "test processing 24499\n",
      "test processing 24999\n",
      "total time : 1836.86800981\n"
     ]
    }
   ],
   "source": [
    "#新输入文本（词的list形式）,生成文本向量\n",
    "#model.infer_vector(['only','you','can','prevent','forecast','fires'])\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "#分别统计训练数据集和测试集的长度\n",
    "train_le = len(train_corpus)\n",
    "test_le = len(test_corpus)\n",
    "\n",
    "columns = [i for i in range(80)]\n",
    "feature = columns[:]\n",
    "columns.append('score')\n",
    "\n",
    "pd_train = pd.DataFrame(columns = columns)\n",
    "pd_test = pd.DataFrame(columns = columns)\n",
    "\n",
    "#以pd.DataFrame构造训练集\n",
    "for i in range(train_le):\n",
    "    content = train_corpus[i]\n",
    "    t1 = time.time()\n",
    "    vec = pv_dbow_model.infer_vector(content.words)\n",
    "    t2 = time.time()\n",
    "    #print 'infer_vector need :',t2-t1\n",
    "    score = train.iloc[i].Score\n",
    "    featurelist = vec.tolist()\n",
    "    featurelist.append(score)\n",
    "    row = pd.DataFrame([featurelist],columns=columns)\n",
    "    #print 'row:',row\n",
    "    pd_train = pd_train.append(row,ignore_index=True)\n",
    "    #print pd_train.head(5)\n",
    "    if i%500 == -1%500:  \n",
    "        print 'train processing %s'%i\n",
    "\n",
    "#以pd.DataFrame构造测试集\n",
    "for i in range(test_le):\n",
    "    content = test_corpus[i]\n",
    "    vec = pv_dbow_model.infer_vector(content)\n",
    "    score = test.iloc[i].Score\n",
    "    featurelist = vec.tolist()\n",
    "    featurelist.append(score)\n",
    "    row = pd.DataFrame([featurelist],columns=columns)\n",
    "    pd_test = pd_test.append(row,ignore_index=True)\n",
    "    if i%500 == -1%500:  \n",
    "        print 'test processing %s'%i\n",
    "\n",
    "t3 = time.time()\n",
    "print 'total time :',t3-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train processing 499\n",
      "train processing 999\n",
      "train processing 1499\n",
      "train processing 1999\n",
      "train processing 2499\n",
      "train processing 2999\n",
      "train processing 3499\n",
      "train processing 3999\n",
      "train processing 4499\n",
      "train processing 4999\n",
      "train processing 5499\n",
      "train processing 5999\n",
      "train processing 6499\n",
      "train processing 6999\n",
      "train processing 7499\n",
      "train processing 7999\n",
      "train processing 8499\n",
      "train processing 8999\n",
      "train processing 9499\n",
      "train processing 9999\n",
      "train processing 10499\n",
      "train processing 10999\n",
      "train processing 11499\n",
      "train processing 11999\n",
      "train processing 12499\n",
      "train processing 12999\n",
      "train processing 13499\n",
      "train processing 13999\n",
      "train processing 14499\n",
      "train processing 14999\n",
      "train processing 15499\n",
      "train processing 15999\n",
      "train processing 16499\n",
      "train processing 16999\n",
      "train processing 17499\n",
      "train processing 17999\n",
      "train processing 18499\n",
      "train processing 18999\n",
      "train processing 19499\n",
      "train processing 19999\n",
      "train processing 20499\n",
      "train processing 20999\n",
      "train processing 21499\n",
      "train processing 21999\n",
      "train processing 22499\n",
      "train processing 22999\n",
      "train processing 23499\n",
      "train processing 23999\n",
      "train processing 24499\n",
      "train processing 24999\n",
      "train processing 25499\n",
      "train processing 25999\n",
      "train processing 26499\n",
      "train processing 26999\n",
      "train processing 27499\n",
      "train processing 27999\n",
      "train processing 28499\n",
      "train processing 28999\n",
      "train processing 29499\n",
      "train processing 29999\n"
     ]
    }
   ],
   "source": [
    "#预测数据转换成doc vec\n",
    "predict_le = len(predict_corpus)\n",
    "\n",
    "columns = [i for i in range(80)]\n",
    "feature = columns[:]\n",
    "\n",
    "pd_predict = pd.DataFrame(columns = columns)\n",
    "\n",
    "#以pd.DataFrame构造预测集\n",
    "for i in range(predict_le):\n",
    "    content = predict_corpus[i]\n",
    "    #t1 = time.time()\n",
    "    vec = pv_dbow_model.infer_vector(content)\n",
    "    #t2 = time.time()\n",
    "    #print 'infer_vector need :',t2-t1\n",
    "    #score = train.iloc[i].Score\n",
    "    featurelist = vec.tolist()\n",
    "    #featurelist.append(score)\n",
    "    row = pd.DataFrame([featurelist],columns=columns)\n",
    "    #print 'row:',row\n",
    "    pd_predict = pd_predict.append(row,ignore_index=True)\n",
    "    #print pd_train.head(5)\n",
    "    if i%500 == -1%500:  \n",
    "        print 'train processing %s'%i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存数据\n",
    "pd_train.to_csv('./data/pd_train.csv',index=False)\n",
    "pd_test.to_csv('./data/pd_test.csv',index=False)\n",
    "pd_predict.to_csv('./data/pd_predict.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
